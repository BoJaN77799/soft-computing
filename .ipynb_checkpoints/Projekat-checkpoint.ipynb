{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6de6c4",
   "metadata": {},
   "source": [
    "# PROJEKAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "777d7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "import os\n",
    "import csv\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dbffcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImageAnd2Gray(path):\n",
    "    img_haar = cv2.imread(path)\n",
    "    return cv2.cvtColor(img_haar, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7cd700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gray_image(image):\n",
    "    plt.imshow(image, 'gray')\n",
    "    \n",
    "def display_image(image):\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145aaa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_coords(image, coords):\n",
    "    cv2.drawContours(image, [coords], -1, (255,255,255), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7f6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np_array(pose_landmarks, el_num=68, dtype=\"int\"):\n",
    "    coords = np.zeros((el_num, 2), dtype=dtype)\n",
    "    \n",
    "    for i in range(0, el_num):\n",
    "        coords[i] = (pose_landmarks.part(i).x, pose_landmarks.part(i).y)\n",
    "    \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0eeac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circle(image, coords):\n",
    "    cv2.circle(image, (coords[0], coords[1]), 25, (255, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98bfcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_faces_with_contures(path):\n",
    "    face_cascade_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    img = loadImageAnd2Gray(path)\n",
    "\n",
    "    faces = face_cascade_classifier.detectMultiScale(img, scaleFactor=1.3, minNeighbors=4, minSize=(30, 30), \n",
    "                                              flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    for (x, y , w ,h) in faces:\n",
    "        face_rect = dlib.rectangle(x, y, x + w, y + h)\n",
    "        aligned_face = align_face(img, face_rect)\n",
    "\n",
    "    display_gray_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e81232b",
   "metadata": {},
   "source": [
    "# Korisne stvari\n",
    "cv2.rectangle(img, (x,y), (x+w, y+h), (0, 0 , 255), 3) -> iscrtavanje faca na ulaznoj slici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58a33a",
   "metadata": {},
   "source": [
    "# Pronalazenje 68 tacaka i cetriranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ef78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_model = \"shape_predictor_68_face_landmarks.dat\"\n",
    "face_pose_predictor = dlib.shape_predictor(predictor_model)\n",
    "DESIRED_LEFT_EYE = (0.35, 0.35)\n",
    "DESIRED_RIGHT_EYE = (0.65, 0.35)\n",
    "DESIRED_FACE_WIDTH = 110\n",
    "DESIRED_FACE_HEIGHT = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ce5ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_face(img, face_rect, verbose=False):\n",
    "\n",
    "    pose_landmarks = face_pose_predictor(img, face_rect)\n",
    "    landmark_coords = to_np_array(pose_landmarks)\n",
    "\n",
    "    left_eye_coords = landmark_coords[36:41]\n",
    "    right_eye_coords = landmark_coords[42:47]\n",
    "    \n",
    "    if verbose:\n",
    "        draw_coords(img, landmark_coords)\n",
    "        draw_coords(img, left_eye_coords)\n",
    "        draw_coords(img, right_eye_coords)\n",
    "\n",
    "    left_eye_center = left_eye_coords.mean(axis=0).astype(\"int\")\n",
    "    right_eye_center = right_eye_coords.mean(axis=0).astype(\"int\")\n",
    "\n",
    "    dx = right_eye_center[1] - left_eye_center[1]\n",
    "    dy = right_eye_center[0] - left_eye_center[0]\n",
    "    angle = np.degrees(np.arctan2(dx, dy)) # - 180\n",
    "\n",
    "    dist = np.sqrt((dx * dx) + (dy * dy))\n",
    "    desiredDist = (DESIRED_RIGHT_EYE[0] - DESIRED_LEFT_EYE[0])\n",
    "    desiredDist *= DESIRED_FACE_WIDTH\n",
    "    scale = desiredDist / dist\n",
    "\n",
    "    eyes_center = (int((left_eye_center[0] + right_eye_center[0]) // 2), int((left_eye_center[1] + right_eye_center[1]) // 2))\n",
    "    M = cv2.getRotationMatrix2D(eyes_center, angle, scale)\n",
    "    tx = DESIRED_FACE_WIDTH * 0.5\n",
    "    ty = DESIRED_FACE_HEIGHT * DESIRED_LEFT_EYE[1]\n",
    "    M[0, 2] += (tx - eyes_center[0])\n",
    "    M[1, 2] += (ty - eyes_center[1])\n",
    "\n",
    "    (w, h) = (DESIRED_FACE_WIDTH, DESIRED_FACE_HEIGHT)\n",
    "    aligned_face = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC)\n",
    "\n",
    "    return aligned_face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e202314c",
   "metadata": {},
   "source": [
    "# Ekstrakcija obelezja hog-om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "493adec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_ROWS = 110\n",
    "IMAGE_COLS = 110\n",
    "NBINS = 9             # broj binova\n",
    "CELL_SIZE = (8, 8)    # broj piksela po celiji\n",
    "BLOCK_SIZE = (3, 3)   # broj celija po bloku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "416f8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = cv2.HOGDescriptor(_winSize=(IMAGE_COLS // CELL_SIZE[1] * CELL_SIZE[1], \n",
    "                                  IMAGE_ROWS // CELL_SIZE[0] * CELL_SIZE[0]),\n",
    "                        _blockSize=(BLOCK_SIZE[1] * CELL_SIZE[1],\n",
    "                                    BLOCK_SIZE[0] * CELL_SIZE[0]),\n",
    "                        _blockStride=(CELL_SIZE[1], CELL_SIZE[0]),\n",
    "                        _cellSize=(CELL_SIZE[1], CELL_SIZE[0]),\n",
    "                        _nbins=NBINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec6ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(hog, aligned_image):\n",
    "    return hog.compute(aligned_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e1819a",
   "metadata": {},
   "source": [
    "# Detekcija face sa haar-om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc77a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6460b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_haar(img, scaleFactor_=1.3, minNeighbors_=4, minSize_=(100, 100), flags_=cv2.CASCADE_SCALE_IMAGE):\n",
    "    face_rects = []\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(img, scaleFactor=scaleFactor_, minNeighbors=minNeighbors_, minSize=minSize_, \n",
    "                                          flags=flags_)\n",
    "    for (x, y , w ,h) in faces:\n",
    "        face_rect = dlib.rectangle(x, y, x + w, y + h)\n",
    "        face_rects.append(face_rect)\n",
    "    \n",
    "    return face_rects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcf8b39",
   "metadata": {},
   "source": [
    "# Detekcija face sa hog-om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac35e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42838ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_hog(img):\n",
    "    faces = face_detector(img, 1)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfc1068",
   "metadata": {},
   "source": [
    "# Ekstrakcija obelezja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52800f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faces(faces, img):\n",
    "    extracted_faces_features = []\n",
    "    \n",
    "    for face_rect in faces:   \n",
    "        aligned_face = align_face(img, face_rect)\n",
    "\n",
    "        extracted_face_features = extract_hog_features(hog, aligned_face)\n",
    "        extracted_faces_features.append(extracted_face_features.flatten())\n",
    "    return extracted_faces_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5c200",
   "metadata": {},
   "source": [
    "# Treniranje modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "701acddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir = \"Train\"\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "current_id = 0\n",
    "label_ids = {}\n",
    "\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        path = os.path.join(root, file)\n",
    "        underscore_idx = os.path.basename(path).find('_')\n",
    "        label = os.path.basename(path)[ : underscore_idx]\n",
    "        \n",
    "        if not label in label_ids.values():\n",
    "            label_ids[current_id] = label\n",
    "            current_id += 1\n",
    "        id_ = label_ids[current_id-1]\n",
    "        \n",
    "        image = loadImageAnd2Gray(path)\n",
    "        faces = detect_faces_haar(image)\n",
    "        \n",
    "        if(len(faces)) != 1:\n",
    "            continue\n",
    "        \n",
    "        hoged = extract_faces(faces, image)\n",
    "        x_train.append(hoged[0])\n",
    "        y_train.append(id_)\n",
    "\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1)\n",
    "svm_model_linear.probability = True\n",
    "svm_model_linear.fit(x_train, y_train)\n",
    "\n",
    "# print(svm_model_linear.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3616c142",
   "metadata": {},
   "source": [
    "# Klasifikatori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49023b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MEAN_VALUES=(78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "def create_blob(crop_img):\n",
    "    return cv2.dnn.blobFromImage(crop_img, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb648c",
   "metadata": {},
   "source": [
    "# Klasifikator pola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16a80a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderProto=\"Classifiers/gender_deploy.prototxt\"\n",
    "genderModel=\"Classifiers/gender_net.caffemodel\"\n",
    "\n",
    "genderList=['Male','Female']\n",
    "\n",
    "genderNet=cv2.dnn.readNet(genderModel,genderProto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08e5cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gender(img_colored, x, y, w, h):\n",
    "        \n",
    "    crop_img = img_colored[y:y+h, x:x+w]\n",
    "    \n",
    "    blob=create_blob(crop_img)\n",
    "    \n",
    "    genderNet.setInput(blob)\n",
    "    genderPreds=genderNet.forward()\n",
    "    gender=genderList[genderPreds[0].argmax()]\n",
    "    \n",
    "    return gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49423e21",
   "metadata": {},
   "source": [
    "# Klasifikator starosti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e11a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "ageProto=\"Classifiers/age_deploy.prototxt\"\n",
    "ageModel=\"Classifiers/age_net.caffemodel\"\n",
    "\n",
    "ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "\n",
    "ageNet=cv2.dnn.readNet(ageModel,ageProto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddf3b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_age(img_colored, x, y, w, h):\n",
    "        \n",
    "    crop_img = img_colored[y:y+h, x:x+w]\n",
    "    \n",
    "    blob=create_blob(crop_img)\n",
    "    \n",
    "    ageNet.setInput(blob)\n",
    "    agePreds=ageNet.forward()\n",
    "    age=ageList[agePreds[0].argmax()]\n",
    "    \n",
    "    return age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82eca92",
   "metadata": {},
   "source": [
    "# Klasifikator za rasu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa6f59c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ethnicity(img_colored, x, y, w, h):\n",
    "    crop_img = img_colored[y:y+h, x:x+w]\n",
    "    try:\n",
    "        result = DeepFace.analyze(crop_img, actions=['race'])\n",
    "    except ValueError:\n",
    "        result = {'dominant_race':\"Unknown\"}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1ed0da",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95189b4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-ce39dec36df5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mgray\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mframe_colored\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "video_path = \"Videos/Scarlett_Downey_video2.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "last_frame_num = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "actors = {}\n",
    "\n",
    "fps_trash_hold = 30\n",
    "current_frame = 0\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    gray  = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_colored = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    faces = detect_faces_haar(gray)\n",
    "    \n",
    "    for face_rect in faces:        \n",
    "        w = face_rect.width()\n",
    "        h = face_rect.height()\n",
    "        x = face_rect.left()\n",
    "        y = face_rect.top()\n",
    "        coords = np.array([[x, y], [x + w, y], [x + w, y + h], [x, y + h]])\n",
    "        draw_coords(frame, coords)\n",
    "        \n",
    "        hoged = extract_faces([face_rect], gray)\n",
    "        \n",
    "        svm_predictions = svm_model_linear.predict_proba(np.array(hoged))\n",
    "        max_idx = np.argmax(svm_predictions)\n",
    "        max_value = svm_predictions[0][max_idx]\n",
    "        \n",
    "        if max_value >= 0.6:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            name = label_ids[max_idx]\n",
    "            name = name.replace('-', ' ')\n",
    "            if name not in actors:\n",
    "                actors[name] = [\"\", \"\", \"\"] \n",
    "            if current_frame == 3 or current_frame%fps_trash_hold == 0:\n",
    "                actors[name][0] = predict_gender(frame_colored, x, y, w, h)\n",
    "                actors[name][1] = predict_age(frame_colored, x, y, w, h)\n",
    "                ethinicity_result = predict_ethnicity(frame_colored, x, y, w, h)\n",
    "                actors[name][2] = ethinicity_result['dominant_race']\n",
    "            color = (255, 255, 255)\n",
    "            stroke = 2\n",
    "            text1 = \"{}\".format(name)\n",
    "            text2 = \"{} {} {}\".format(actors[name][0], actors[name][1], actors[name][2])\n",
    "            cv2.putText(frame, text1, (x,y - 40), font, 0.5, color, stroke, cv2.LINE_AA)\n",
    "            cv2.putText(frame, text2, (x,y - 20), font, 0.5, color, stroke, cv2.LINE_AA)\n",
    "            \n",
    "    cv2.imshow('frame',frame)\n",
    "    if last_frame_num == current_frame:\n",
    "        break\n",
    "    current_frame += 1\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaca935",
   "metadata": {},
   "source": [
    "# Rename script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66eb0c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_pictures(image_dir, name, begin_idx = 1):\n",
    "    name = name + '_'\n",
    "    jpeg = \".jpeg\"\n",
    "    i = begin_idx\n",
    "    for filename in os.listdir(image_dir):\n",
    "        file_to_rename_path = image_dir + \"/\" + filename\n",
    "        new_name = image_dir + \"/\" + name + str(i) + jpeg\n",
    "        os.rename(file_to_rename_path, new_name)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7735343",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_pictures(\"Videos/Boseman\", \"Chadwick-Boseman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e836728",
   "metadata": {},
   "source": [
    "# Convert video to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea5019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_images(video_path, dest_dir):\n",
    "    last_frame_num = None\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    image_name = video_path[video_path.find('/')+1:video_path.find('.')-1]\n",
    "    print(image_name)\n",
    "    i = 1\n",
    "    last_frame_num = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    print(last_frame_num)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        cv2.imwrite(dest_dir +\"/\"+ image_name + \"_\" + str(i) +\".jpeg\", frame)\n",
    "        if last_frame_num == i:\n",
    "            break\n",
    "        i += 1\n",
    "    cap.release()\n",
    "    #video_to_images(\"Videos/Tom-Holland-video1_Trimmed2.mp4\", \"Videos/Frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a6b4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scarlett_Downey_video\n",
      "423.0\n"
     ]
    }
   ],
   "source": [
    "video_to_images(\"Videos/Scarlett_Downey_video2.mp4\", \"Videos/Frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf11e12",
   "metadata": {},
   "source": [
    "# Evaluacija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc3c84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(csv_path, full_evaluation=False):\n",
    "    frames = {}\n",
    "    \n",
    "    with open(csv_path, mode ='r') as file:\n",
    "        \n",
    "        csvFile = csv.reader(file)\n",
    "\n",
    "        for line in csvFile:\n",
    "            img_name = line[5]\n",
    "            label = line[0]\n",
    "            underscore_idx = img_name.rfind('_')\n",
    "            dot_idx = img_name.rfind('.')\n",
    "            id = eval(img_name[underscore_idx + 1 : dot_idx])\n",
    "            \n",
    "            if id not in frames:\n",
    "                frames[id] = {}\n",
    "            if full_evaluation:\n",
    "                frames[id][label] = [line[1], line[2], line[3], line[4], line[8], line[9], line[10]]\n",
    "            else:\n",
    "                frames[id][label] = [line[1], line[2], line[3], line[4]]   \n",
    "            \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47e33e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    xA = max(boxA[0][0], boxB[0][0])\n",
    "    yA = max(boxA[1][1], boxB[1][1])\n",
    "    xB = min(boxA[2][0], boxB[2][0])\n",
    "    yB = min(boxA[3][1], boxB[3][1])\n",
    "\n",
    "    interArea = (xB - xA) * (yB - yA)\n",
    "\n",
    "    boxAArea = (boxA[2][0] - boxA[0][0]) * (boxA[3][1] - boxA[1][1])\n",
    "    boxBArea = (boxB[2][0] - boxB[0][0]) * (boxB[3][1] - boxB[1][1])\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bb60034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_evaluation_results(tp, tn, fp, fn):\n",
    "    print(\"True positive: {}\".format(tp))\n",
    "    print(\"True negative: {}\".format(tn))\n",
    "    print(\"False positive: {}\".format(fp))\n",
    "    print(\"False negative: {}\".format(fn))\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_score = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    print(\"Precision: {}\".format(precision))\n",
    "    print(\"Recall: {}\".format(recall))\n",
    "    print(\"F score: {}\".format(f_score))\n",
    "    \n",
    "    return precision, recall, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a0d3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_evaluation_condition(annotated_values, frame_colored, x, y, w, h, full_evaluation=False):\n",
    "    if not full_evaluation: \n",
    "        return True\n",
    "    \n",
    "    gender = predict_gender(frame_colored, x, y, w, h)\n",
    "    age = predict_age(frame_colored, x, y, w, h)\n",
    "    ethnicity_result = predict_ethnicity(frame_colored, x, y, w, h)\n",
    "    ethnicity = ethnicity_result['dominant_race']\n",
    "    \n",
    "    return annotated_values[4] == gender and annotated_values[5].contains(age) and annotated_values[6].contains(ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "640ed6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(csv_path, video_path, classification_prob = 0.6, detetion_prob = 0.7, full_evaluation=False):\n",
    "    \n",
    "    frames = load_csv(csv_path)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    last_frame_num = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    i = 1 # current_frame_id\n",
    "    \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    while True:        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        gray  = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_colored = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        faces = detect_faces_haar(gray)\n",
    "\n",
    "        if i not in frames and len(faces) == 0: # nema labeliranih i nema detektovanih lica\n",
    "            tn += 1\n",
    "            i += 1\n",
    "            continue\n",
    "        if i in frames and len(faces) == 0: # ima labeliranih ali nema detektovanih lica\n",
    "            fn += len(frames[i].keys()) # sva lica koja nije nasao\n",
    "            i += 1\n",
    "            continue\n",
    "        if i not in frames and len(faces) > 0: # nema labeliranih ali ima detektovanih\n",
    "            fp += len(faces) # sva lica koja je nasao\n",
    "            i += 1\n",
    "            continue\n",
    "            \n",
    "        # postoji bar jedno detektovano lice i  postoji bar jedno labelirano lice\n",
    "        for face_rect in faces:        \n",
    "            w1 = face_rect.width()\n",
    "            h1 = face_rect.height()\n",
    "            x1 = face_rect.left()\n",
    "            y1 = face_rect.top()\n",
    "            \n",
    "            hoged = extract_faces([face_rect], gray)\n",
    "\n",
    "            svm_predictions = svm_model_linear.predict_proba(np.array(hoged))\n",
    "            max_idx = np.argmax(svm_predictions)\n",
    "            max_value = svm_predictions[0][max_idx]\n",
    " \n",
    "            if max_value >= classification_prob:                # Nas klasifikator je nasao nesto\n",
    "                name = label_ids[max_idx]\n",
    "                if name in frames[i]:                   # Nas klasifikator je nasao nesto sto je anotirano\n",
    "                    x2 = eval(frames[i][name][0])\n",
    "                    y2 = eval(frames[i][name][1])\n",
    "                    w2 = eval(frames[i][name][2])\n",
    "                    h2 = eval(frames[i][name][3])\n",
    "                    iou = bb_intersection_over_union([(x1, y1), (x1 + w1, y1), (x1 + w1, y1 + h1), (x1, y1 + h1)],\n",
    "                                                     [(x2, y2), (x2 + w2, y2), (x2 + w2, y2 + h2), (x2, y2 + h2)])\n",
    "                    \n",
    "                    if iou > detetion_prob and full_evaluation_condition(\n",
    "                            frames[i][name], frame_colored, x1, y1, w1, h1, full_evaluation):                         \n",
    "                                                                \n",
    "                        tp += 1 # postoji detektovano lice, labelirano je i jeste zadovoljio uslov\n",
    "                    else:                                      \n",
    "                        fp += 1 # postoji detektovano lice i labelirano je, ali nije zadovoljio uslov\n",
    "                else:\n",
    "                    fp += 1 # postoji detektovano lice ali ono nije labelirano\n",
    "            \n",
    "            else:\n",
    "                fn += 1 # postoji labelirano lice ali klasifikator nije siguran sta je\n",
    "                \n",
    "        if last_frame_num == i:\n",
    "            break\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    cap.release()\n",
    "    display_evaluation_results(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdd981d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 590\n",
      "True negative: 97\n",
      "False positive: 149\n",
      "False negative: 278\n",
      "Precision: 0.7983761840324763\n",
      "Recall: 0.6797235023041475\n",
      "F score: 0.7342874922215308\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-39d8a6f64663>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Labels/base-evaluation/dinner_labels.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Videos/test/Dinner_scene_Trimmed_37.mp4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Labels/full-evaluation/dinner_labels_refactored.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Videos/test/Dinner_scene_Trimmed_37.mp4\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-e1be358ab72c>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(csv_path, video_path, classification_prob, detetion_prob, full_evaluation)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m                     if iou > detetion_prob and full_evaluation_condition(\n\u001b[1;32m---> 59\u001b[1;33m                             frames[i][name], frame_colored, x1, y1, w1, h1, full_evaluation):                         \n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                         \u001b[0mtp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;31m# postoji detektovano lice, labelirano je i jeste zadovoljio uslov\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-c0d971d7c7c9>\u001b[0m in \u001b[0;36mfull_evaluation_condition\u001b[1;34m(annotated_values, frame_colored, x, y, w, h, full_evaluation)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0methnicity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0methnicity_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dominant_race'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mannotated_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgender\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mannotated_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mannotated_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0methnicity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "evaluate(\"Labels/base-evaluation/dinner_labels.csv\", \"Videos/test/Dinner_scene_Trimmed_37.mp4\")\n",
    "print(\"-\"*100)\n",
    "evaluate(\"Labels/full-evaluation/dinner_labels_refactored.csv\", \"Videos/test/Dinner_scene_Trimmed_37.mp4\", 0.6, 0.7, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ceacf5",
   "metadata": {},
   "source": [
    "# Refactoring labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7090abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(line):\n",
    "    line_string = \"\"\n",
    "    for el in line: \n",
    "        line_string += el + ','\n",
    "    return line_string[:-1]\n",
    "\n",
    "def refactor_labels_csv(csv_path, dest_path, actors):\n",
    "    dest_file_path = dest_path + '/' + csv_path[csv_path.rfind('/'): csv_path.find('.')] + \"_refactored.csv\"\n",
    "    with open(csv_path, mode ='r') as file1:\n",
    "        with open(dest_file_path, mode ='w') as file2:\n",
    "            csvFile = csv.reader(file1)\n",
    "            for line in csvFile:\n",
    "                if line[0] in actors:\n",
    "                    line.append(actors[line[0]][0])\n",
    "                    line.append(actors[line[0]][1])\n",
    "                    line.append(actors[line[0]][2])\n",
    "                    file2.write(list_to_string(line) +'\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9208d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "actors = {\n",
    "#         'Tom-Holland': ['Male', '(15-20)', 'white'],\n",
    "        'Scarlett-Johansson': ['Female', '(25-32)', 'white'],\n",
    "        'Robert-Downey-Junior': ['Male', '(38-43)|(48-53)', 'white|latino hispanic'],\n",
    "#         'Benedict-Cumberbatch' :['Male', '(38-43)', 'white']\n",
    "    }\n",
    "# actors = {\n",
    "#         'Emma-Watson': ['Female', '(15-20)|(25-32)', 'white']\n",
    "#     }\n",
    "refactor_labels_csv('Labels/base-evaluation/scarlett_downey_video2_labels.csv', \"Labels/full-evaluation\", actors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
