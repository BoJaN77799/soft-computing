{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6de6c4",
   "metadata": {},
   "source": [
    "# Detekcija, lokalizacija i prepoznavanje glumaca na video isečcima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "777d7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "from scipy.integrate import simps\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dbffcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImageAnd2Gray(path):\n",
    "    img_haar = cv2.imread(path)\n",
    "    return cv2.cvtColor(img_haar, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7cd700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gray_image(image):\n",
    "    plt.imshow(image, 'gray')\n",
    "    \n",
    "def display_image(image):\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145aaa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_coords(image, coords):\n",
    "    cv2.drawContours(image, [coords], -1, (255,255,255), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7f6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np_array(pose_landmarks, el_num=68, dtype=\"int\"):\n",
    "    coords = np.zeros((el_num, 2), dtype=dtype)\n",
    "    \n",
    "    for i in range(0, el_num):\n",
    "        coords[i] = (pose_landmarks.part(i).x, pose_landmarks.part(i).y)\n",
    "    \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d98bfcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_faces_with_contures(path):\n",
    "    face_cascade_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    img = loadImageAnd2Gray(path)\n",
    "\n",
    "    faces = face_cascade_classifier.detectMultiScale(img, scaleFactor=1.3, minNeighbors=4, minSize=(30, 30), \n",
    "                                              flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    for (x, y , w ,h) in faces:\n",
    "        face_rect = dlib.rectangle(x, y, x + w, y + h)\n",
    "        aligned_face = align_face(img, face_rect)\n",
    "\n",
    "    display_gray_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62eadd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_ids():\n",
    "    label_ids = {\n",
    "        0: 'Angelina-Jolie', \n",
    "        1: 'Benedict-Cumberbatch', \n",
    "        2: 'Brad-Pitt', \n",
    "        3: 'Chadwick-Boseman', \n",
    "        4: 'Emma-Watson', \n",
    "        5: 'Keanu-Reeves', \n",
    "        6: 'Robert-Downey-Junior', \n",
    "        7: 'Scarlett-Johansson', \n",
    "        8: 'Tom-Holland'\n",
    "    }\n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58a33a",
   "metadata": {},
   "source": [
    "# Pronalaženje 68 tacaka i centriranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ef78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_model = \"shape_predictor_68_face_landmarks.dat\"\n",
    "face_pose_predictor = dlib.shape_predictor(predictor_model)\n",
    "DESIRED_LEFT_EYE = (0.35, 0.35)\n",
    "DESIRED_RIGHT_EYE = (0.65, 0.35)\n",
    "DESIRED_FACE_WIDTH = 110\n",
    "DESIRED_FACE_HEIGHT = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ce5ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_face(img, face_rect, verbose=False):\n",
    "\n",
    "    pose_landmarks = face_pose_predictor(img, face_rect)\n",
    "    landmark_coords = to_np_array(pose_landmarks)\n",
    "\n",
    "    left_eye_coords = landmark_coords[36:41]\n",
    "    right_eye_coords = landmark_coords[42:47]\n",
    "    \n",
    "    if verbose:\n",
    "        draw_coords(img, landmark_coords)\n",
    "        draw_coords(img, left_eye_coords)\n",
    "        draw_coords(img, right_eye_coords)\n",
    "\n",
    "    left_eye_center = left_eye_coords.mean(axis=0).astype(\"int\")\n",
    "    right_eye_center = right_eye_coords.mean(axis=0).astype(\"int\")\n",
    "\n",
    "    dx = right_eye_center[1] - left_eye_center[1]\n",
    "    dy = right_eye_center[0] - left_eye_center[0]\n",
    "    angle = np.degrees(np.arctan2(dx, dy)) # - 180\n",
    "\n",
    "    dist = np.sqrt((dx * dx) + (dy * dy))\n",
    "    desiredDist = (DESIRED_RIGHT_EYE[0] - DESIRED_LEFT_EYE[0])\n",
    "    desiredDist *= DESIRED_FACE_WIDTH\n",
    "    scale = desiredDist / dist\n",
    "\n",
    "    eyes_center = (int((left_eye_center[0] + right_eye_center[0]) // 2), int((left_eye_center[1] + right_eye_center[1]) // 2))\n",
    "    M = cv2.getRotationMatrix2D(eyes_center, angle, scale)\n",
    "    tx = DESIRED_FACE_WIDTH * 0.5\n",
    "    ty = DESIRED_FACE_HEIGHT * DESIRED_LEFT_EYE[1]\n",
    "    M[0, 2] += (tx - eyes_center[0])\n",
    "    M[1, 2] += (ty - eyes_center[1])\n",
    "\n",
    "    (w, h) = (DESIRED_FACE_WIDTH, DESIRED_FACE_HEIGHT)\n",
    "    aligned_face = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC)\n",
    "\n",
    "    return aligned_face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e202314c",
   "metadata": {},
   "source": [
    "# Ekstrakcija obelezja hog-om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "493adec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_ROWS = 110\n",
    "IMAGE_COLS = 110\n",
    "NBINS = 9             # broj binova\n",
    "CELL_SIZE = (8, 8)    # broj piksela po celiji\n",
    "BLOCK_SIZE = (3, 3)   # broj celija po bloku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "416f8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = cv2.HOGDescriptor(_winSize=(IMAGE_COLS // CELL_SIZE[1] * CELL_SIZE[1], \n",
    "                                  IMAGE_ROWS // CELL_SIZE[0] * CELL_SIZE[0]),\n",
    "                        _blockSize=(BLOCK_SIZE[1] * CELL_SIZE[1],\n",
    "                                    BLOCK_SIZE[0] * CELL_SIZE[0]),\n",
    "                        _blockStride=(CELL_SIZE[1], CELL_SIZE[0]),\n",
    "                        _cellSize=(CELL_SIZE[1], CELL_SIZE[0]),\n",
    "                        _nbins=NBINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec6ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(hog, aligned_image):\n",
    "    return hog.compute(aligned_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e1819a",
   "metadata": {},
   "source": [
    "# Detekcija face sa haar-om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc77a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6460b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_haar(img, scaleFactor_=1.3, minNeighbors_=4, minSize_=(100, 100), flags_=cv2.CASCADE_SCALE_IMAGE):\n",
    "    face_rects = []\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(img, scaleFactor=scaleFactor_, minNeighbors=minNeighbors_, minSize=minSize_, \n",
    "                                          flags=flags_)\n",
    "    for (x, y , w ,h) in faces:\n",
    "        face_rect = dlib.rectangle(x, y, x + w, y + h)\n",
    "        face_rects.append(face_rect)\n",
    "    \n",
    "    return face_rects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcf8b39",
   "metadata": {},
   "source": [
    "# Detekcija face sa hog-om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac35e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42838ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_hog(img):\n",
    "    faces = face_detector(img, 1)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfc1068",
   "metadata": {},
   "source": [
    "# Ekstrakcija obelezja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52800f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faces(faces, img):\n",
    "    extracted_faces_features = []\n",
    "    \n",
    "    for face_rect in faces:   \n",
    "        aligned_face = align_face(img, face_rect)\n",
    "\n",
    "        extracted_face_features = extract_hog_features(hog, aligned_face)\n",
    "        extracted_faces_features.append(extracted_face_features.flatten())\n",
    "    return extracted_faces_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3616c142",
   "metadata": {},
   "source": [
    "# Klasifikatori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49023b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MEAN_VALUES=(78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "def create_blob(crop_img):\n",
    "    return cv2.dnn.blobFromImage(crop_img, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb648c",
   "metadata": {},
   "source": [
    "# Klasifikator pola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16a80a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderProto=\"Classifiers/gender_deploy.prototxt\"\n",
    "genderModel=\"Classifiers/gender_net.caffemodel\"\n",
    "\n",
    "genderList=['Male','Female']\n",
    "\n",
    "genderNet=cv2.dnn.readNet(genderModel,genderProto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08e5cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gender(img_colored, x, y, w, h):\n",
    "        \n",
    "    crop_img = img_colored[y:y+h, x:x+w]\n",
    "    \n",
    "    blob=create_blob(crop_img)\n",
    "    \n",
    "    genderNet.setInput(blob)\n",
    "    genderPreds=genderNet.forward()\n",
    "    gender=genderList[genderPreds[0].argmax()]\n",
    "    \n",
    "    return gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49423e21",
   "metadata": {},
   "source": [
    "# Klasifikator starosti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e11a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "ageProto=\"Classifiers/age_deploy.prototxt\"\n",
    "ageModel=\"Classifiers/age_net.caffemodel\"\n",
    "\n",
    "ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "\n",
    "ageNet=cv2.dnn.readNet(ageModel,ageProto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddf3b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_age(img_colored, x, y, w, h):\n",
    "        \n",
    "    crop_img = img_colored[y:y+h, x:x+w]\n",
    "    \n",
    "    blob=create_blob(crop_img)\n",
    "    \n",
    "    ageNet.setInput(blob)\n",
    "    agePreds=ageNet.forward()\n",
    "    age=ageList[agePreds[0].argmax()]\n",
    "    \n",
    "    return age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82eca92",
   "metadata": {},
   "source": [
    "# Klasifikator za rasu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa6f59c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ethnicity(img_colored, x, y, w, h):\n",
    "    crop_img = img_colored[y:y+h, x:x+w]\n",
    "    try:\n",
    "        result = DeepFace.analyze(crop_img, actions=['race'])\n",
    "    except ValueError:\n",
    "        result = {'dominant_race':\"Unknown\"}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaca935",
   "metadata": {},
   "source": [
    "# Rename script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66eb0c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_pictures(image_dir, name, begin_idx = 1):\n",
    "    name = name + '_'\n",
    "    jpeg = \".jpeg\"\n",
    "    i = begin_idx\n",
    "    for filename in os.listdir(image_dir):\n",
    "        file_to_rename_path = image_dir + \"/\" + filename\n",
    "        new_name = image_dir + \"/\" + name + str(i) + jpeg\n",
    "        os.rename(file_to_rename_path, new_name)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e836728",
   "metadata": {},
   "source": [
    "# Convert video to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ea5019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_images(video_path, dest_dir):\n",
    "    last_frame_num = None\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    image_name = video_path[video_path.find('/')+1:video_path.find('.')]\n",
    "    i = 1\n",
    "    last_frame_num = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imwrite(dest_dir +\"/\"+ image_name + \"_\" + str(i) +\".jpeg\", frame)\n",
    "        if last_frame_num == i:\n",
    "            break\n",
    "        i += 1\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99faeab0",
   "metadata": {},
   "source": [
    "# Video from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db0d6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_from_images(img_array, video_path, size):\n",
    "    out = cv2.VideoWriter(video_path,cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ceacf5",
   "metadata": {},
   "source": [
    "# Refactoring labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7090abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(line):\n",
    "    line_string = \"\"\n",
    "    for el in line: \n",
    "        line_string += el + ','\n",
    "    return line_string[:-1]\n",
    "\n",
    "def refactor_labels_csv(csv_path, dest_path, actors):\n",
    "    dest_file_path = dest_path + '/' + csv_path[csv_path.rfind('/'): csv_path.find('.')] + \"_refactored.csv\"\n",
    "    with open(csv_path, mode ='r') as file1:\n",
    "        with open(dest_file_path, mode ='w') as file2:\n",
    "            csvFile = csv.reader(file1)\n",
    "            for line in csvFile:\n",
    "                if line[0] in actors:\n",
    "                    line.append(actors[line[0]][0])\n",
    "                    line.append(actors[line[0]][1])\n",
    "                    line.append(actors[line[0]][2])\n",
    "                    file2.write(list_to_string(line) +'\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9208d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "# actors = {\n",
    "#         'Tom-Holland': ['Male', '(15-20)', 'white'],\n",
    "#         'Scarlett-Johansson': ['Female', '(25-32)', 'white'],\n",
    "#         'Robert-Downey-Junior': ['Male', '(38-43)|(48-53)', 'white|latino hispanic'],\n",
    "#         'Benedict-Cumberbatch' :['Male', '(38-43)', 'white']\n",
    "#         'Brad-Pitt':['Male', '(38-43)', 'white|latino hispanic']\n",
    "#         'Emma-Watson': ['Female', '(15-20)|(25-32)', 'white']\n",
    "#     }\n",
    "# refactor_labels_csv('Labels/base-evaluation/brad-pitt-video_1_trimmed.csv', \"Labels/full-evaluation\", actors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5c200",
   "metadata": {},
   "source": [
    "# Treniranje modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "701acddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(c, image_dir=\"Train\"):\n",
    "    print(\" << Training started >> \")\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    current_id = 0\n",
    "    label_ids = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(image_dir):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file)\n",
    "            underscore_idx = os.path.basename(path).find('_')\n",
    "            label = os.path.basename(path)[ : underscore_idx]\n",
    "\n",
    "            if not label in label_ids.values():\n",
    "                label_ids[current_id] = label\n",
    "                current_id += 1\n",
    "            id_ = label_ids[current_id-1]\n",
    "\n",
    "            image = loadImageAnd2Gray(path)\n",
    "            faces = detect_faces_haar(image)\n",
    "\n",
    "            if(len(faces)) != 1:\n",
    "                continue\n",
    "\n",
    "            hoged = extract_faces(faces, image)\n",
    "            x_train.append(hoged[0])\n",
    "            y_train.append(id_)\n",
    "\n",
    "    svm_model_linear = SVC(kernel = 'linear', C = c)\n",
    "    svm_model_linear.probability = True\n",
    "    svm_model_linear.fit(x_train, y_train)\n",
    "    print(\" << Training ended >> \")\n",
    "    return svm_model_linear, label_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d702880b",
   "metadata": {},
   "source": [
    "# Merenje fps-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e5f3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_fps(video_path, full_evaluation=False):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    last_frame_num = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    \n",
    "    current_frame = 0\n",
    "    \n",
    "    startTime = time.time() # starting measuring\n",
    "    while True:\n",
    "\n",
    "        if last_frame_num == current_frame-1:\n",
    "            break\n",
    "            \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if frame is None:\n",
    "            break\n",
    "            \n",
    "        gray  = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        frame_colored = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        faces = detect_faces_haar(gray)\n",
    "\n",
    "        for face_rect in faces:        \n",
    "            w = face_rect.width()\n",
    "            h = face_rect.height()\n",
    "            x = face_rect.left()\n",
    "            y = face_rect.top()\n",
    "            coords = np.array([[x, y], [x + w, y], [x + w, y + h], [x, y + h]])\n",
    "            draw_coords(frame, coords)\n",
    "\n",
    "            hoged = extract_faces([face_rect], gray)\n",
    "\n",
    "            svm_predictions = svm_model_linear.predict_proba(np.array(hoged))\n",
    "            max_idx = np.argmax(svm_predictions)\n",
    "            max_value = svm_predictions[0][max_idx]\n",
    "\n",
    "            if max_value >= 0.6:\n",
    "                name = label_ids[max_idx]\n",
    "                name = name.replace('-', ' ')\n",
    "                if full_evaluation:\n",
    "                    predict_gender(frame_colored, x, y, w, h)\n",
    "                    predict_age(frame_colored, x, y, w, h)\n",
    "                    predict_ethnicity(frame_colored, x, y, w, h)\n",
    "\n",
    "        current_frame += 1\n",
    "        \n",
    "        # stopping video\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return (time.time() - startTime), current_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf11e12",
   "metadata": {},
   "source": [
    "# Evaluacija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc3c84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(csv_path, full_evaluation=False):\n",
    "    frames = {}\n",
    "    \n",
    "    with open(csv_path, mode ='r') as file:\n",
    "        \n",
    "        csvFile = csv.reader(file)\n",
    "\n",
    "        for line in csvFile:\n",
    "            img_name = line[5]\n",
    "            label = line[0]\n",
    "            underscore_idx = img_name.rfind('_')\n",
    "            dot_idx = img_name.rfind('.')\n",
    "            id = eval(img_name[underscore_idx + 1 : dot_idx])\n",
    "            \n",
    "            if id not in frames:\n",
    "                frames[id] = {}\n",
    "            if full_evaluation:\n",
    "                frames[id][label] = [line[1], line[2], line[3], line[4], line[8], line[9], line[10]]\n",
    "            else:\n",
    "                frames[id][label] = [line[1], line[2], line[3], line[4]]   \n",
    "            \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47e33e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    xA = max(boxA[0][0], boxB[0][0])\n",
    "    yA = max(boxA[1][1], boxB[1][1])\n",
    "    xB = min(boxA[2][0], boxB[2][0])\n",
    "    yB = min(boxA[3][1], boxB[3][1])\n",
    "\n",
    "    interArea = (xB - xA) * (yB - yA)\n",
    "\n",
    "    boxAArea = (boxA[2][0] - boxA[0][0]) * (boxA[3][1] - boxA[1][1])\n",
    "    boxBArea = (boxB[2][0] - boxB[0][0]) * (boxB[3][1] - boxB[1][1])\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5911d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_evaluation_results(tp, tn, fp, fn, mAP, fps):\n",
    "    print(\"\\t\\tTrue positive: {}\".format(tp))\n",
    "    print(\"\\t\\tTrue negative: {}\".format(tn))\n",
    "    print(\"\\t\\tFalse positive: {}\".format(fp))\n",
    "    print(\"\\t\\tFalse negative: {}\".format(fn))\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_score = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    print(\"\\t\\tPrecision: {}\".format(precision))\n",
    "    print(\"\\t\\tRecall: {}\".format(recall))\n",
    "    print(\"\\t\\tF score: {}\".format(f_score))\n",
    "    print(\"\\t\\tmAP: {}\".format(mAP))\n",
    "    print(\"\\t\\tModel proccessed FPS: {}\".format(fps))\n",
    "    \n",
    "    return precision, recall, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e0c16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_evaluation_condition(annotated_values, frame_colored, x, y, w, h, full_evaluation=False):\n",
    "    if not full_evaluation: \n",
    "        return True\n",
    "    \n",
    "    gender = predict_gender(frame_colored, x, y, w, h)\n",
    "    age = predict_age(frame_colored, x, y, w, h)\n",
    "    ethnicity_result = predict_ethnicity(frame_colored, x, y, w, h)\n",
    "    ethnicity = ethnicity_result['dominant_race']\n",
    "    \n",
    "    return annotated_values[4] == gender and (age in annotated_values[5]) and (ethnicity in annotated_values[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4daba9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mAP(precision_over_classes):\n",
    "    sum = 0\n",
    "    num_of_neg_sum = 0\n",
    "    for key in precision_over_classes:\n",
    "        if precision_over_classes[key][0] == 0:\n",
    "            num_of_neg_sum += 1\n",
    "        sum += precision_over_classes[key][0]\n",
    "    return sum/(len(precision_over_classes.keys())-num_of_neg_sum)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54ac29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_precision(precision_by_name):\n",
    "    c_tp = precision_by_name[1]\n",
    "    c_fp = precision_by_name[2]\n",
    "    c_fn = precision_by_name[3]\n",
    "    if (c_tp + c_fp) == 0: \n",
    "        precision_by_name[0] = 0\n",
    "    elif (c_tp + c_fn) == 0:\n",
    "        precision_by_name[1] = 0\n",
    "    else:\n",
    "        precision_by_name[5] = (c_tp/(c_tp + c_fp), c_tp/(c_tp + c_fn))\n",
    "    x1 = precision_by_name[4][0]\n",
    "    x2 = precision_by_name[5][0]\n",
    "    y1 = precision_by_name[4][1]\n",
    "    y2 = precision_by_name[5][1]\n",
    "    precision_by_name[0] += simps(np.array([y1, y2]), dx=(x2 - x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "640ed6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(svm_model_linear, label_ids, csv_path, video_path, classification_prob = 0.6, detetion_prob = 0.7, full_evaluation=False):\n",
    "    print(\"\\t<Evaluation video='{}'>\".format(csv_path))\n",
    "    frames = load_csv(csv_path, full_evaluation)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    last_frame_num = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    i = 1 # current_frame_id\n",
    "    \n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    \n",
    "    precision_over_classes = {} # key = actor, value = [sum, tp, fp, fn, (precision_k-1, recall_k-1), (precision_k, recall_k)] \n",
    "    \n",
    "    while True:        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        gray  = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_colored = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        faces = detect_faces_haar(gray)\n",
    "\n",
    "        if i not in frames and len(faces) == 0: # nema labeliranih i nema detektovanih lica\n",
    "            tn += 1\n",
    "            i += 1\n",
    "            continue\n",
    "        if i in frames and len(faces) == 0: # ima labeliranih ali nema detektovanih lica\n",
    "            fn += len(frames[i].keys()) # sva lica koja nije nasao\n",
    "            for key in frames[i]:\n",
    "                if key not in precision_over_classes:\n",
    "                    precision_over_classes[key] = [0, 0, 0, 0, [0, 0], [0, 0]]\n",
    "                precision_over_classes[key][3] += 1\n",
    "            i += 1\n",
    "            continue\n",
    "        if i not in frames and len(faces) > 0: # nema labeliranih ali ima detektovanih\n",
    "            fp += len(faces) # sva lica koja je nasao\n",
    "            i += 1\n",
    "            continue\n",
    "            \n",
    "        # postoji bar jedno detektovano lice i  postoji bar jedno labelirano lice\n",
    "        for face_rect in faces:        \n",
    "            w1 = face_rect.width()\n",
    "            h1 = face_rect.height()\n",
    "            x1 = face_rect.left()\n",
    "            y1 = face_rect.top()\n",
    "            \n",
    "            hoged = extract_faces([face_rect], gray)\n",
    "\n",
    "            svm_predictions = svm_model_linear.predict_proba(np.array(hoged))\n",
    "            max_idx = np.argmax(svm_predictions)\n",
    "            max_value = svm_predictions[0][max_idx]\n",
    "            name = label_ids[max_idx]\n",
    "            \n",
    "            if max_value >= classification_prob:                # Nas klasifikator je nasao nesto\n",
    "                if name not in precision_over_classes:\n",
    "                    precision_over_classes[name] = [0, 0, 0, 0, [0, 0], [0, 0]]\n",
    "                if name in frames[i]:                   # Nas klasifikator je nasao nesto sto je anotirano\n",
    "                    x2 = eval(frames[i][name][0])\n",
    "                    y2 = eval(frames[i][name][1])\n",
    "                    w2 = eval(frames[i][name][2])\n",
    "                    h2 = eval(frames[i][name][3])\n",
    "                    iou = bb_intersection_over_union([(x1, y1), (x1 + w1, y1), (x1 + w1, y1 + h1), (x1, y1 + h1)],\n",
    "                                                     [(x2, y2), (x2 + w2, y2), (x2 + w2, y2 + h2), (x2, y2 + h2)])\n",
    "                    \n",
    "                    if iou > detetion_prob and full_evaluation_condition(\n",
    "                            frames[i][name], frame_colored, x1, y1, w1, h1, full_evaluation):                         \n",
    "                                                                \n",
    "                        tp += 1 # postoji detektovano lice, labelirano je i jeste zadovoljio uslov\n",
    "                        precision_over_classes[name][1] +=1\n",
    "                    else:                                      \n",
    "                        fp += 1 # postoji detektovano lice i labelirano je, ali nije zadovoljio uslov\n",
    "                        precision_over_classes[name][2] +=1\n",
    "                else:\n",
    "                    fp += 1 # postoji detektovano lice ali ono nije labelirano\n",
    "                    precision_over_classes[name][2] +=1\n",
    "            else:\n",
    "                fn += 1 # postoji labelirano lice ali klasifikator nije siguran sta je\n",
    "                if name in precision_over_classes: \n",
    "                    precision_over_classes[name][3] +=1\n",
    "            if name in precision_over_classes:    \n",
    "                calculate_average_precision(precision_over_classes[name])\n",
    "                precision_over_classes[name][4] = precision_over_classes[name][5]\n",
    "\n",
    "        if last_frame_num == i:\n",
    "            break\n",
    "        \n",
    "        i += 1 # next frame\n",
    "    \n",
    "    cap.release()\n",
    "    mAP = eval_mAP(precision_over_classes)\n",
    "    exec_time, frame_count = measure_fps(video_path, full_evaluation)\n",
    "    fps = frame_count/exec_time\n",
    "    precision, recall, f_score = display_evaluation_results(tp, tn, fp, fn, mAP, fps)\n",
    "    print(\"\\t</Evaluation>\\n\".format(csv_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1a52e",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95189b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(svm_model_linear, label_ids, video_path, full=False, save_demo=False):\n",
    "    print(\"<< Demo started >>\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    last_frame_num = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    fps_trash_hold = 30\n",
    "    current_frame = 0\n",
    "\n",
    "    # CREATE DEMO PARAMS\n",
    "    img_array = [] # image_array for creating video\n",
    "    height, width, layers = 0, 0, 0\n",
    "    size = (width, height)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if last_frame_num == current_frame-1:\n",
    "            break\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "        gray  = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        frame_colored = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        faces = detect_faces_haar(gray)\n",
    "\n",
    "        for face_rect in faces:        \n",
    "            w = face_rect.width()\n",
    "            h = face_rect.height()\n",
    "            x = face_rect.left()\n",
    "            y = face_rect.top()\n",
    "            coords = np.array([[x, y], [x + w, y], [x + w, y + h], [x, y + h]])\n",
    "            draw_coords(frame, coords)\n",
    "\n",
    "            hoged = extract_faces([face_rect], gray)\n",
    "\n",
    "            svm_predictions = svm_model_linear.predict_proba(np.array(hoged))\n",
    "            max_idx = np.argmax(svm_predictions)\n",
    "            max_value = svm_predictions[0][max_idx]\n",
    "\n",
    "            if max_value >= 0.6:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                name = label_ids[max_idx].replace('-', ' ')\n",
    "                color = (255, 255, 255)\n",
    "                stroke = 2\n",
    "                text_name = \"{}\".format(name)\n",
    "                cv2.putText(frame, text_name, (x,y - 40), font, 0.5, color, stroke, cv2.LINE_AA)\n",
    "                if full:\n",
    "                    gender = predict_gender(frame_colored, x, y, w, h)\n",
    "                    age = predict_age(frame_colored, x, y, w, h)\n",
    "                    ethnicity_result = predict_ethnicity(frame_colored, x, y, w, h)\n",
    "                    ethnicity = ethnicity_result['dominant_race']\n",
    "                    text_gae = \"{} {} {}\".format(gender, age, ethnicity)\n",
    "                    cv2.putText(frame, text_gae, (x,y - 20), font, 0.5, color, stroke, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        if save_demo:\n",
    "            if size[0] == 0: # first time size update\n",
    "                height, width, layers = frame.shape\n",
    "                size = (width,height)\n",
    "            img_array.append(frame)\n",
    "\n",
    "        current_frame += 1\n",
    "        # stopping video\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"<< Demo ended >>\")\n",
    "    if save_demo:\n",
    "        print(\"<< Saving demo >>\")\n",
    "        video_name = video_path[video_path.rfind('/')+1:video_path.rfind('.')]\n",
    "        create_video_from_images(img_array, \"Videos/demo/\"+video_name+\"_demo.avi\", size)\n",
    "        print(\"<< Demo saved >>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1ed0da",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8cc73be",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path_base = \"Labels/base-evaluation/\"\n",
    "csv_path_full = \"Labels/full-evaluation/\"\n",
    "video_path_valid = \"Videos/validation/\"\n",
    "video_path_test = \"Videos/test/\"\n",
    "\n",
    "# label_ids = create_label_ids()\n",
    "# # treniranje modela\n",
    "#svm_model_linear, label_ids = train_model(5)\n",
    "\n",
    "# # ucitavanje modela\n",
    "# filename = 'Models/svm_model.sav'\n",
    "# pickle.dump(svm_model_linear, open(filename, 'wb'))\n",
    "# svm_model_linear = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# validacija\n",
    "# print(\"<Evaluations>\\n\")\n",
    "\n",
    "# evaluate(svm_model_linear, label_ids, csv_path_base + \"brad-pitt-video_1_trimmed.csv\", video_path_valid + \"Brad-Pitt_video1_Trimmed.mp4\")\n",
    "# # evaluate(svm_model_linear, label_ids, csv_path_full + \"brad-pitt-video_1_trimmed_refactored.csv\", video_path_valid + \"Brad-Pitt_video1_Trimmed.mp4\", \n",
    "# #          full_evaluation=True)\n",
    "\n",
    "# evaluate(svm_model_linear, label_ids, csv_path_base + \"avengers_12s.csv\", video_path_valid + \"avengers_12sec.mp4\")\n",
    "# # # evaluate(svm_model_linear, label_ids, csv_path_full + \"avengers_refactored.csv\", video_path_valid + \"avengers_12sec.mp4\", \n",
    "# # #          full_evaluation=True)\n",
    "\n",
    "# evaluate(svm_model_linear, label_ids, csv_path_base + \"rdj_holland.csv\", video_path_valid + \"Tom-Holland-video2-Trimmed.mp4\")\n",
    "# # # evaluate(svm_model_linear, label_ids, csv_path_full + \"rdj_holland_refactored.csv\", video_path_valid + \"Tom-Holland-video2-Trimmed.mp4\", \n",
    "# # #          full_evaluation=True)\n",
    "\n",
    "# evaluate(svm_model_linear, label_ids, csv_path_base + \"scarlett_downey_video2_labels.csv\", video_path_valid + \"Scarlett_Downey_video2.mp4\")\n",
    "# # # evaluate(svm_model_linear, label_ids, csv_path_full + \"scarlett_downey_video2_labels_refactored.csv\", video_path_valid + \"Scarlett_Downey_video2.mp4\", \n",
    "# # #          full_evaluation=True)\n",
    "\n",
    "# print(\"</Evaluations>\")\n",
    "\n",
    "# print(\"<Tests>\\n\")\n",
    "\n",
    "# # test\n",
    "# evaluate(svm_model_linear, label_ids, csv_path_base + \"dinner_labels.csv\", video_path_test + \"Dinner_scene_Trimmed_37.mp4\")\n",
    "# evaluate(svm_model_linear, label_ids, csv_path_full + \"dinner_labels_refactored.csv\", video_path_test + \"Dinner_scene_Trimmed_37.mp4\", \n",
    "#          full_evaluation=True)\n",
    "\n",
    "# evaluate(svm_model_linear, label_ids, csv_path_base + \"emma-watson-labels.csv\", video_path_test + \"Emma-Watson_video2_Trimmed.mp4\")\n",
    "# evaluate(svm_model_linear, label_ids, csv_path_full + \"emma-watson-labels_refactored.csv\", video_path_test + \"Emma-Watson_video2_Trimmed.mp4\", \n",
    "#           full_evaluation=True)\n",
    "\n",
    "# print(\"</Tests>\")\n",
    "\n",
    "# # demo\n",
    "# demo(svm_model_linear, label_ids, video_path_valid + \"Scarlett_Downey_video2.mp4\", full=False, save_demo=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
